{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Basic time series handling in Python\n",
    "\n",
    "**Name**: \n",
    "\n",
    "**Student number**:\n",
    "\n",
    "**Semester**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this first exercise is to give you the fundamentals for working with timeseries data in Python. We will learn how to import a timeseries, visualize it and perform basic statistics.\n",
    "\n",
    "During these exercises you should also learn to read documentation and user guides of large Python libraries and packages (useful collections of prewritten code). We encourage you to really try to understand these first-hand resources before googling for solutions or asking for help. Knowing how to quickly and reliably get the information you need from a documentation can save you a lot of time and frustration in any further programming project. Most documentation pages feature a section with examples at their bottom, which can be quite handy, especially if you are not yet familiar with the syntax or just started out with learning programming languages.\n",
    "\n",
    "Having this in mind, our goal is not to give you a complete tutorial on every function in Python but to get you ready for learning on your own and guide you in the right direction. \n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Before we get started with Python, if you have never worked with a Jupyter Notebook or Google Colaboratory before, take some time to get familiar with the working environment. Generally, a Jupyter Notebook is an interactive Notebook that allows you to write code, run code, document your work and present your results. All in one document. \n",
    "A Jupyter Notebook is divided into cells. There are different types of cells, e.g. Code cells allow you to write and run Python code, and Markdown cells can display formatted Notes writen in Markdown. The introductory notebook https://colab.research.google.com/notebooks/intro.ipynb will get you started with Google Colab. \n",
    "\n",
    "## Basics for working with python libraries\n",
    "\n",
    "### Classes and objects\n",
    "\n",
    "Python is an *object-oriented* programming language. This means that almost anything in Python is an *object*. An object is a particular instance of a *class*. You might think of yourself as an instance of the class \"Human\". Classes define the basic *attributes/properties* (that a human has a name, an age, a mood, etc.) and fundamental behaviour (how humans react to certain stimuli) of an object. Objects each have a copy of the attributes of their class with a specific value (e.g., `.name=\"Martin\", .age=20, .mood=\"happy\"`) and these influence their behaviour (e.g., an angry human might react differently to a happy human). \n",
    "Python is an *object-oriented* programming language. This means that almost anything in Python is an *object*. An object is a particular instance of a *class*. You might think of yourself as an instance of the class \"Human\". Classes define the basic *attributes/properties* (that a human has a name, an age, a mood, etc.) and fundamental behaviour (how humans react to certain stimuli) of an object. Objects each have a copy of the attributes of their class with a specific value (e.g., `.name=\"Martin\", .age=20, .mood=\"angry\"`) and these influence their behaviour (e.g., an angry human might react differently to a happy human). \n",
    "\n",
    "### Variables\n",
    "\n",
    "*Variables* \"store\" objects (i.e., they reference a certain object and provide access to its attributes and methods). Note that the same object can be stored in multiple variables. If variable `a` and `b` refer to the same object, and we change one of its attributes through accessing `a`, then the same change will occur in the variable `b`.\n",
    "\n",
    "In the following example, `a` is set to refer to a newly created list object. Then `b` is set to refer to the same object as `a`. If we now change an attribute of this object (such as an element of the list), the change is seen in both variables `a` and `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0, 1, 2]\n",
    "b = a\n",
    "print(\"b =\", b)\n",
    "a[0] = -1\n",
    "print(\"b =\", b)\n",
    "print(\"b has changed even though we've been modifying a!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not happen when `a` is later set to refer to a completely different object. In the next example, `a` is first set to refer to the integer object `1`. When `a` is later set to refer to the integer object `2`, the other variable `b` will not have changed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = a\n",
    "print(\"b =\", b)\n",
    "a = 2\n",
    "print(\"b =\", b)\n",
    "print(\"b has not changed by making a refer to another object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods and functions \n",
    "\n",
    "- *Functions* are set of instructions to perform some task. Functions **can** take objects as arguments and *return* either nothing (There is a special Python object called `None` that represents \"nothing\"), or some object(s). For instance, a function `to_days(years)` might take a number of years (integer number) and return the equivalent number of days. \n",
    "- *Methods* on the other hand are functions that are tied to an object and they often modify it, e.g., the method `change_mood(mood)` might take a string such as \"happy\" and set the attribute `.mood` of its object to this input string, while returning nothing (`None`).\n",
    "- *Arguments/Parameters* are the inputs a function or method might accept or even need to perform its task. Depending on the way a function is constructed, arguments may be just given as objects, or with keywords that give the name of the parameter. For example, `to_days(years, months)` could be called as `to_days(5,3)` by just using objects as arguments, or as `to_days(years=5, months=3)` with keyword arguments. When using keyword arguments, the order can be changed, so executing `to_days(months=3, years=5)` would give the same result. That would not be tha case when executing `to_days(3, 5)`! \n",
    "\n",
    "#### Notation\n",
    "\n",
    "- *Attributes* can be accessed by `object.attribute` (e.g, `Martin.name` will give you the string `\"Martin\"`). If the object returned by the attribute has an attribute itself these can also be by dot-notation (e.g., `Martin.pet.name` will give you `\"Bello\"`, while `Martin.pet` will give you the object corresponding to `Bello`, which is Martin's dog and an instance of the class `Pet`).\n",
    "- *Functions* are independent of objects and classes and are simply executed by their name with parentheses, as `function()`.\n",
    "- *Methods* are accessed by `object.method()`.\n",
    "- *Positional arguments* have to be provided after each other in the right order, e.g., `sum_up(<number1>, <number2>, <number3>, ...)`. Note that `<number1>` is a placeholder for an actual number like 2, not a keyword.\n",
    "- *Keyword arguments* can be supplied in any order and are recognized by their *keyword*, e.g., `add_up(secondnumber=<number>, firstnumber=<number>)`.\n",
    "- *Objects returned from methods and functions*. To get the output of a method write `myvariable = object.method()`, or `myvariable1, myvariable2 = object.method()` if multiple objects are returned.\n",
    "\n",
    "## Data handling with Pandas\n",
    "\n",
    "### Importing the Pandas library\n",
    "\n",
    "Before we can visualize or analyze our timeseries, we need to load it into Python. For this, we will use Pandas, a powerful Python library for handling tabular data. You can find some useful information on Pandas in the introduction at https://pandas.pydata.org/docs/getting_started/index.html, the user guide at https://pandas.pydata.org/docs/user_guide/index.html, and the pandas reference documentation at https://pandas.pydata.org/docs/reference/index.html, which provides the details to every class, function and method that is included with Pandas. \n",
    "\n",
    "First, let's import Pandas itself to use it in our notebook! For that, make a new Python code cell below and enter `import pandas as pd` (this imports the pandas module and stores it in a variable which I named `pd` by convention). In order to verify that the import worked, enter `print(pd.__version__)` on the next line and run the code cell. You should now see the version number of pandas as an output below the code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You just accessed your first attribute (`.__version__`) and supplied it to the `print()` function as a positional argument. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builtin documentation\n",
    "\n",
    "Most Python libraries have a detailed builtin documentation. In Jupyter, this documentation can be accessed by writing a question mark `?` after an object reference (for example a variable name, or package name). Jupyter then prints the documentation for this object.\n",
    "\n",
    "This can be applied to packages, classes, objects, or methods. For packages, it typically shows general package documentation, for classes or objects the documentation of the class, and for methods the call interface (arguments to be provided when calling the function) and any documentation of the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading your timeseries\n",
    "\n",
    "Now we are ready to load our data and turn it into a `DataFrame` object (i.e., Pandas' representation of a table). First, you need to put your datafile in the same directory as the notebook file, for example by uploading it to the JupyterHub server.\n",
    "\n",
    "**Task 1:** Look up the function `read_csv` in the documentation at https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html or in the user guide (https://pandas.pydata.org/docs/user_guide/io.html#io-read-csv-table) and try to import your timeseries with it by entering something like `mydata = pd.read_csv('mydata.csv')` into a new code cell or on a new line above. When executed, this code will run the `read_csv` function and store it's output in a variable, which I called `mydata`. When you imported your data, call Python's `type()` function on your data variable to check if the variable indeed references an object of the `DataFrame` class/type.\n",
    "\n",
    "*Note: When you run the new code make sure that the `import pandas as pd` statement was executed before. The order by which code cells were executed is indicated by the number in the square brackets besides each code cell. If something doesn't work, it's often advisable to use the \"Run All\" cells button.*\n",
    "\n",
    "*Hint: You may need to specify the `sep` parameter to tell pandas how to separate the columns in your csv-file, and the `comment` or `skiprows` parameter to ignore lines at the beginning of the csv-file that do not contain tabular data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = pd.read_csv(...) # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easy way to view the first and last few rows of a dataframe is by running the methods [`DataFrame.head`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html) or [`DataFrame.tail`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html) on our DataFrame object. Let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be able to see some rows of the dataframe. Also make sure the columns are named correctly, otherwise you might have to use additional optional parameters with the `read_csv` function (e.g., specify the `header` parameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing: selecting data from a dataframe\n",
    "\n",
    "Row indices explicitly identify each row in a dataframe and allow quick data retrieval. Together with column labels (= column indices) we can use them to extract any subset of our data set. In Pandas there are different ways (i.e., indexing operators) to select data from a DataFrame:\n",
    "\n",
    "- `DataFrame.loc[]` (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html): Used to select rows and/or columns by their row labels (taken from the row index column) and column labels, e.g., `DataFrame.loc[\"2022-01-01\", \"temperature\"]` to select the entry stored at the row `2022-01-01` and the column `temperature`. \n",
    "- `DataFrame.iloc[]` (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html): Used to select rows and/or columns by their integer positions in the data table (e.g, `DataFrame.iloc[:5, 1]` to select the values of the 2nd column in the first 5 rows of a DataFrame). Note that these indices are *zero-based*, meaning that the first element is accessed by 0.\n",
    "- `DataFrame[]` (alias `DataFrame.__getitem__()`): Allows both label and position inputs but provides less functionality then `.loc` and `.iloc`. Unfortunately, this method is only poorly documented. \n",
    "\n",
    "*Note: Indexing operators such as `.loc, .iloc and []` are a special type of method that uses square brackets `[...]` instead of round parentheses.*\n",
    "\n",
    "**Task 2:** Using the information provided at https://pandas.pydata.org/docs/user_guide/indexing.html and in the documentation for `.loc` and `.iloc`, select the following subframes from your dataframe using indexing:\n",
    "\n",
    "1. Select the 7th row from your dataframe.\n",
    "2. Select the first 10 values from a single column of your choice.\n",
    "3. Select all values from two columns that are in the 7th to 10th (i.e., 7th, 8th, 9th and 10th row) row.\n",
    "4. If your data has multiple timeseries in subsequent rows (e.g., different sampling sites, species, ...), choose one timeseries and select the corresponding rows only.\n",
    "4. Select all rows where the value for a column of your choice is above some threshold.\n",
    "\n",
    "*Hint: You can \"chain\" selections, meaning that you can select from a previous selection, e.g. as an extreme example, `mydata[...].loc[...][...].iloc[...]`*.\n",
    "\n",
    "Any selection can be stored in a new variable by just assigning it to a new variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting a time index\n",
    "\n",
    "Pandas has numerous functionalities that make dealing with timeseries data sets more convenient. A comprehensive list of it's timeseries specifics can be found at https://pandas.pydata.org/docs/user_guide/timeseries.html. One functionality which is especially useful is that we can use a timestamp from our data set as an *index*. This can be done in different ways. \n",
    "\n",
    "**Task 3:** Since you have already created your DataFrame, you can make use of the method [`DataFrame.set_index`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html). Read it's documentation and set the column that defines time in your data set as the new index for your DataFrame. Use the [`DataFrame.index`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.index.html#pandas.DataFrame.index) attribute to verify that the reassignment worked.\n",
    "\n",
    "Now you can use timesteps as indexes. With that, implement the following selections:\n",
    "\n",
    "1. Select all rows that fall between two time points. If your index is a DatetimeIndex (see also next section in this exercise) you can use the [`pd.Timestamp()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html) to define a time point.\n",
    "2. Select every second row within a time window.\n",
    "3. Select the values from two columns that fall within a time window and where the value of one of these columns is above a threshold. \n",
    "\n",
    "**Bonus Task:** Try to convert the time component in your data set (might be 1 or more columns) to Pandas' [`DatetimeIndex`](https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.html#pandas.DatetimeIndex) class with help of the [`to_datetime`](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) function. Use the DatetimeIndex as the DataFrame's index. If you need to create a new column you can do so by writing `mydataframe[\"new-column-name\"] = ...` You may also have a look at the next section first an come back later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a suitable subset of the data for further analysis\n",
    "\n",
    "**Task 4:**\n",
    "Come up with a selection that appears to be reasonable for your data set and store the result in a variable (i.e., new DataFrame). We will visualize this selected portion of your data in the next section. Also shortly explain why you think this selection makes sense (1-2 sentences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have selected the data we want and stored it in a DataFrame, let's export it as a CSV-file. For that use the [`DataFrame.to_csv`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html) method. Choose either a comma or a tab as a column separator and save the file in the data folder in your working directory. Note that if your row index is a Pandas' `DatetimeIndex` you can now specify the `date_format` parameter to format dates in the CSV-file as you like (e.g., `date_format='%Y-%m-%d'` to get \"1974-05-17\"). Also make sure that `index=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting data with matplotlib\n",
    "\n",
    "### Your first plot\n",
    "\n",
    "In this section, we will now visualize our timeseries with `matplotlib`. Matplotlib is one of Python's most popular libraries for data visualization and quite powerful. In its gallery (https://matplotlib.org/stable/gallery/index.html), you can find many helpful examples that demonstrate the diversity of visualizations you can achieve with matplotlib. \n",
    "\n",
    "Also have a look at the user guide (https://matplotlib.org/stable/users/index.html), which will get you started. \n",
    "\n",
    "The first step in using matplotlib is to import `pyplot` (as `plt` by convention), the submodule we will be using for constructing our plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyplot allows us to create a plot and then modify it and add elements to it. To get started make a simple plot of one of your columns with respect to the time index (accessible via `DataFrame.index`) using the [`plot`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html) method of pyplot. *Remember that you can select a single column of your DataFrame using `DataFrame[\"column-label\"]`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(...) # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have just created your first plot in one line of code. \n",
    "\n",
    "### Creating a figure with multiple plots\n",
    "\n",
    "Pyplot also allows us to easily create multiple plots at once in one figure, which is very convenient when you got more than one timeseries that you want to plot separately or prepare figures for your publication. The basic code structure for plotting multiple such *subplots* in one figure looks like this:\n",
    "\n",
    "`fig, axs = plt.subplots(nrows, ncols, figsize=(width, height))` \n",
    "\n",
    "Here we define how many subplots we want in our figure (e.g., specify `nrows=2` and `ncols=1` to stack two subplots vertically). The `figsize` parameter allows us to control the dimensions of the whole figure by defining it's width and height in inches. Subplots will be resized automatically. Note that `plt.subplots` returns a `Figure` object (for modifying the whole figure) and an array of `Axes` objects (i.e., a list of `Axes` objects by which we can access and modify individual subplots), which we named `fig` and `axs` above.  \n",
    "\n",
    "**Task 5:** Plot two columns at once, each against time. If you get stuck you can consult the sholt deme of the use of `subplots` at https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html .\n",
    "\n",
    "*Note: With the Axes array you can use indexing to access the individual subplots, e.g., `axs[1].plot()` to plot on the second one. When both `nrows>1` and `ncols>1`, the Axis array will be two-dimensional and you need to write `axs[i, j]` to access a single subplot.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(...) # TODO\n",
    "axs[0].plot(...) # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These graphs look great but they are still meaningless to anyone unfamiliar with the data. \n",
    "\n",
    "#### Adding axis labels and titles\n",
    "\n",
    "**Task 6:** Add meaningful labels to both axes of each subplot using [`Axes.set_xlabel`](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_xlabel.html) and [`Axes.set_ylabel`](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_ylabel.html). Don't forget to also specify the units (if any) of your displayed quantities! Further, provide a title for each subplot with [`Axes.set_title`](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.axes.Axes.set_title.html) and perhaps also a title for the whole figure with [`Figure.suptitle`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.suptitle.html). Add these modifications to the code cell where you defined your figure.\n",
    "\n",
    "*Tip: Try to set `tight_layout=True` or `sharex=True` without setting a label for the x-axis to avoid text overlaps between graphs and remove redundant information from the figure.*\n",
    "\n",
    "#### Adding a legend\n",
    "\n",
    "A Legend helps to discriminate the contents of a plot and are vital when your plot contains different symbols and lines. To add a legend to your plot you can use the [`Axes.legend`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.legend.html) method. An easy and robust way to add labels (i.e., content descriptions) to your legend is by setting the `label` parameter every time you add a new element to your plot. Then, creating the legend is as simple as adding `Axes.legend()`.\n",
    "\n",
    "**Task 7:** Add a horizontal red line to your first subplot by writing [`Axes.axhline`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.axhline.html)`(position-on-y-axis, color=\"red\", label=\"my threshold\")`. Then, set the `label` also in your `.plot` method and create the legend. Use the `loc` parameter of `Axes.legend` to tell matplotlib where to put your legend.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Styling plots\n",
    "\n",
    "Now that we know how to properly set up plots, let's focus a bit on style. \n",
    "As you know by now, by default, `.plot` will connect neighboring data points with lines. These lines can be styled by passing properties (i.e., attributes) of the [`Line2D`](https://matplotlib.org/stable/api/_as_gen/matplotlib.lines.Line2D.html#matplotlib.lines.Line2D) class as arguments directly to the `.plot` method. For instance, you can change the standard line to a red dashed line with a width of 1.5pt by setting `.plot(..., linestyle='--', linewidth=1.5, color='red')`. \n",
    "\n",
    "Sometimes it´s better to not connect data points by lines but plot them as individual points/markers. For this, matplotlib offers the method `.scatter` (https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html), which works similar to `.plot` but produces a scatter plot. For instance, to make a plot with black X-markers of size 8pt, write `.scatter(marker='x', s=8**2, c='black')`. A list of available markers can be found at the `.plot` documentation page (https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html).\n",
    "\n",
    "*Note: In principle, you can also produce a scatter plot by declaring, e.g., `.plot(x, y, 'o')`, but it´s recommended to use `.scatter` for this purpose, since it allows more control such as defining a marker size for each data point. However, to plot markers and connect them by lines, e.g., use `.plot(x, y, '.:')`. More information on format strings (`fmt`) like `'o'` and `'.:'` can be found at the bottom of the [`.plot` documentation page](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html).* \n",
    "\n",
    "**Task 8:** Copy the code of your figure to a new code cell and modify it by changing the style. Use `.scatter` for one subplot, and `.plot` for the other. Experiment with different parameters to change their style. Get creative! The goal of this task is to familiarize yourself with different styling options and **not** to produce a perfect ready-to-publish figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to sometimes increase readability of a plot is to add a grid to the plotting area. Write [`axs[i].grid()`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.grid.html) to add a grid to the $i$-th subplot. Just like `.plot`, the `.grid` method also accepts `Line2D` properties as parameters to style grid lines. To render the grid lines behind markers and plotted lines, add [`axs[i].set_axisbelow(True)`](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_axisbelow.html#matplotlib-axes-axes-set-axisbelow). \n",
    "\n",
    "Now that we have finished our figure, let´s save it to a file. Using [`Figure.savefig`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html)`('exercise1_figure1', format='png')`, save your figure as a PNG to the new folder. \n",
    "\n",
    "*Note: You can pass `bbox_inches='tight'` to `Figure.savefig` and set a value for `pad_inches`, to add some whitespace around the figure.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(...) # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statistics with NumPy\n",
    "\n",
    "Numpy (https://numpy.org/) is one of the most powerful and popular Python packages for statistical analysis and performing numerical computations in general.\n",
    "\n",
    "### Numpy arrays\n",
    "\n",
    "The fundamental object in numpy is an \"array\". Generally, numpy arrays are collections of objects of the same type. Each array has a certain dimension. For instance, with a dimension of 1 and a float type (e.g., `np.float64`) the array is equivalent to a vector, $v \\in \\mathbb{R}^d$. With dimension 2, an array represents a matrix,  $A \\in \\mathbb{R}^{(n\\times m)}$. A two-dimensional numpy array is also very similar to a pandas DataFrame. In most cases, arrays will have numerical type and either one or two dimensions. However, in general you can also create a numpy array that stores text and they may have any arbitrary number of dimensions. \n",
    "\n",
    "An array also has a `shape`, which defines how many objects/numbers it can store along which dimension. E.g., an array of shape `(2, 4)` is analogous to a table/dataframe with 2 rows (1st dimension) and 4 columns (2nd dimension), thus, it can store a total of $2\\cdot 4 = 8$ objects, which is it´s `size`. \n",
    "\n",
    "To use numpy we first need to import it (this is done as `np` by convention). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a quick look at the user guide at https://numpy.org/devdocs/user/basics.creation.html and create a simple two-dimensional array (= `np.ndarray` class) using the [`np.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html) function and assign it to a variable (e.g., `myarray = np.array(...)`). Put in any numbers you like. Note that you do not have to specify a `dtype` (by default, numpy will choose a reasonable data type based on your input). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myarray = np.array(...) # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the data type, the shape and the size of your array by printing the `.dtype`, `.shape` and `.size` on your variable. Use python's `print()` function to output all attributes in one code cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often it is important to make sure that a newly created array uses floating point numbers as datatype. To ensure that, it is useful to give at least one of the numbers in the lists for creation as floating point numbers.\n",
    "\n",
    "Compare the data type and actual entries of two arrays, one created from the list `[1, 2, 3]`, the other created from the list `[1.0, 2, 3]`. Interpret the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "a1 = np.array(...)\n",
    "a2 = np.array(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like on Pandas' DataFrame, we can use positional indexing to access certain objects within a numpy ndarray. E.g., `myarray[i, j]` (or `myarray[i][j]`) will return the number stored at the i-th row and j-th column. To get a subset of a row/column use the \":\"-notation, e.g., `myarray[::2, 2:5]` to get every second number from the 3rd to 5th column. \n",
    "The User Guide (https://numpy.org/doc/stable/user/basics.indexing.html) provides more information on indexing numpy arrays. \n",
    "\n",
    "You can use almost any mathematical operation on numerical arrays you can think of, as long as their shapes are compatible. Just a few examples: \n",
    "\n",
    "- Add a scalar constant to every number in an array: `a + 1` or `np.add(a, 1)`\n",
    "- Add up numbers from two arrays of identical shape: `a + b` or `np.add(a, b)`\n",
    "- Multiply numbers from two arrays element-wise (hadamard product): `a * b` or `np.multiply(a, b)`\n",
    "- Dot product between two arrays (matrix multiplication): `a @ b` or `np.dot(a, b)` or `a.dot(b)`\n",
    "- Transpose an array: `a.transpose()` or `a.T`\n",
    "- Natural logarithm of every element: `np.log(a)`\n",
    "- Maximum/Minimum value in an array: `np.max(a)/np.min(a)`\n",
    "\n",
    "At https://numpy.org/doc/stable/reference/routines.math.html you can find more available mathematical operations you can use on numpy arrays. \n",
    "\n",
    "Numpy also has several methods for statistical analysis, such as:\n",
    "\n",
    "- Average of an array: `np.mean(a)`\n",
    "- Average of an array weighted by another: `np.average(a, weights=b)`\n",
    "- Variance of an array: `np.var(a)`\n",
    "- Standard deviation of an array: `np.std(a)`\n",
    "- Compute the covariance matrix: `np.cov(a)`. For this, the rows correspond to different random variables, and the columns to different realizations of the same random variable. The covariance matrix will be a square matrix with number of rows and columns equal to the number of rows of `a`. Alternatively, it can be used as `np.cov(a, b)`, to compute the covariance matrix of two variables with realizations given in `a` and `b`.\n",
    "\n",
    "A list of methods related to statistics can be found at https://numpy.org/doc/stable/reference/routines.statistics.html.\n",
    "\n",
    "*Note: By specifying the `axis` parameter in each one of these methods, you can also compute the metric along specific dimensions (e.g., `np.mean(a, axis=0)` will compute the average along the rows and output an array with averages for every column in a 2D array).*\n",
    "\n",
    "**Task 9:** \n",
    "\n",
    "1. Select a time range from a column in your pandas dataframe. Calculate the mean and standard deviation (square root of variance) of the data in that timeframe. Make a plot with the data, mean, and mean +- the standard deviation.\n",
    "\n",
    "2. Then select another time range from the same column that is shifted by some $\\Delta t$. Assign the data from the two time ranges to two variables and compute the covariance between them using numpy. Make sure that the selected ranges have the same size. Observe how changing $\\Delta t$ affects the covariance.\n",
    "\n",
    "*Note: You can use numpy methods on pandas subframes just like you would on numpy arrays. However, in some cases pandas subframes are treated differently. To ensure that you get an output that is exactly the same for an equivalent numpy array use pandas' [`DataFrame.to_numpy()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html), which explicitly converts subframes to numpy arrays.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sample generation\n",
    "\n",
    "If you need to test an analysis method or visualization it's often easier to quickly generate random samples than find and import a suitable data set. Functions for random sampling are available in numpy's submodule [np.random](https://numpy.org/doc/stable/reference/random/index.html?highlight=random%20sampling%20numpy%20random#module-numpy.random). \n",
    "\n",
    "To use it we first need to create a Random Number *Generator* (RNG) object. We will do this by writing `rng = `[`np.random.default_rng()`](https://numpy.org/doc/stable/reference/random/generator.html#numpy.random.default_rng). Note that this method takes a single **optional** parameter, `seed`, which determines the random state. In other words, if we set seed to any integer number and run the code multiple times, the result will always be the same.\n",
    "\n",
    "With the Generator created and assigned to the variable `rng` we can now use any of its methods, like so: `rng.method_name()`.\n",
    "\n",
    "**Task 10:** Create a Random Number Generator object and use it to generate samples drawn from a Gaussian (normal) distribution with the [`.normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.normal.html#numpy.random.Generator.normal) method. Choose any values for the mean, standard deviation and sample size by using the keyword arguments `loc`, `scale`, and `size` appropriately. Assign the output (i.e., the generated samples) to a variable and use numpy's `np.mean` and `np.std` functions to calculate the mean and standard deviation. Observe the difference between the mean and standard deviation of your samples and the values you entered into `.normal`. Quickly describe how the size parameter influences the difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "rng = np.random.default_rng()\n",
    "samples = rng.normal(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b915c1e8519984f5c2cc39f643b09545a3d456cdd86028d3d390b2173d2860f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
